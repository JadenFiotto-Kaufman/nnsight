{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d66d5e6-d3ba-42c8-9b07-04e6c635ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdaf9b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 666/666 [00:00<00:00, 145kB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 17.3MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 51.9MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 34.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = nnsight.LanguageModel(\"gpt2-large\", device_map=\"cuda:0\")\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8fd0748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "params.pt: 100%|██████████| 236M/236M [00:05<00:00, 39.9MB/s] \n",
      "lens/gpt2-large/config.json: 100%|██████████| 198/198 [00:00<00:00, 76.2kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "from lens.lens import TunedLens\n",
    "lens = TunedLens(model)\n",
    "lens.load_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd3efddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1280)\n",
       "    (wpe): Embedding(1024, 1280)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-35): 36 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "415fe6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 3.25G/3.25G [00:42<00:00, 77.0MB/s]\n",
      "generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 26.1kB/s]\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "def decoder(x):\n",
    "    # decoder consists of final layer norm + unembedding\n",
    "    return model.lm_head(model.transformer.ln_f(x))\n",
    "    # return model.lm_head(x)\n",
    "\n",
    "saved = []\n",
    "\n",
    "with model.invoke(\"it was the best of times, it was the worst of times\") as invoker:\n",
    "    for layer in range(len(model.transformer.h)):\n",
    "        out = model.transformer.h[layer].output[0]\n",
    "        saved.append(decoder(lens(out, layer)).save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed3bd652",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = [s.value.detach().cpu() for s in saved]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9059f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "for s in saved:\n",
    "    temp = []\n",
    "    s = s.softmax(-1).argmax(-1)\n",
    "    for c in s:\n",
    "        temp.append(tokenizer.decode(c))\n",
    "\n",
    "    new.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2166e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[', a entry best opportunity times the was not moment worst expectation times'],\n",
       " ['\\xa0 a the to the, and. a., the,'],\n",
       " [', a\\n of the, and was a\\n, the,'],\n",
       " ['ous a\\n of the, and was a world, the,'],\n",
       " ['ine a\\n way the, and was a right thing the,'],\n",
       " ['ish a first of the, and was a first of the,'],\n",
       " ['- a first way the, and was a first of the.'],\n",
       " ['- a first way the, but was a first of the.'],\n",
       " ['- a first way the, but was a first thing the.'],\n",
       " ['- a first way the, but was a first thing the.'],\n",
       " ['� not first way the, but was a first thing the.'],\n",
       " [\"� a first way the, but's a first of the.\"],\n",
       " [\"� not first way the, but's a perfect of the,\"],\n",
       " [\"� not first way the, but's a perfect of the,\"],\n",
       " [\"� not first way the, but's a perfect of the,\"],\n",
       " [\"� not first way the, but's a perfect of the,\"],\n",
       " [\"� a first way the and and's a perfect of luck,\"],\n",
       " [\"� a first way the, and's a perfect of luck,\"],\n",
       " [\"� a first way the, and's a perfect of luck,\"],\n",
       " [\"rd a first thing the, and's the worst of times,\"],\n",
       " [\"rd a first way the, and's the worst of times,\"],\n",
       " [\" alike a first way the, and's the worst of times,\"],\n",
       " [' alike a first way the, and was the worst of times,'],\n",
       " [' alike a first thing the, and was the worst of times,'],\n",
       " [\" alike a first thing the, and's the worst of times,\"],\n",
       " [' alike a first thing the, and was the worst of times,'],\n",
       " [' Skydragon a first thing the, and was the worst of times.\"'],\n",
       " [' Skydragon a first thing the, and was the worst of times,'],\n",
       " [' Skydragon a first thing the, and was the worst of times,'],\n",
       " [' srfAttach a first thing the, it was the worst of times.'],\n",
       " [' in a first thing times, it was the worst of times.'],\n",
       " [' in a first thing the, it was the worst of times,'],\n",
       " [' in a first thing times, it was the worst of times.'],\n",
       " [', a first of times, it was the worst of times.'],\n",
       " [', a first of times, it was the worst of times.'],\n",
       " [\"'s a first thing times, it was the worst of times.\"]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
